{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35fdf26",
   "metadata": {},
   "source": [
    "### This notebook will used for model development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f41b6",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47d4f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vinay\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler       # scaling\n",
    "from sklearn.model_selection import train_test_split   # spiltting the data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression    # model building algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier    # ensemble algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from keras.models import Sequential                    # neural network\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "                                                       # evalution metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve, recall_score, precision_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV       # hyperparameter tuning\n",
    "\n",
    "from imblearn.over_sampling import SMOTE               # for handling imbalamce data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "197864dc",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pip install --upgrade scikit-learn imbalanced-learn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2589d127",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139344d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Senior Citizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Phone Service</th>\n",
       "      <th>Multiple Lines</th>\n",
       "      <th>Internet Service</th>\n",
       "      <th>Online Security</th>\n",
       "      <th>Online Backup</th>\n",
       "      <th>Device Protection</th>\n",
       "      <th>Tech Support</th>\n",
       "      <th>Streaming TV</th>\n",
       "      <th>Streaming Movies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Paperless Billing</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Monthly Charges</th>\n",
       "      <th>Total Charges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Senior Citizen  Partner  Dependents  Tenure  Phone Service  \\\n",
       "0          0               0        1           0       1              0   \n",
       "1          1               0        0           0      34              1   \n",
       "2          1               0        0           0       2              1   \n",
       "3          1               0        0           0      45              0   \n",
       "4          0               0        0           0       2              1   \n",
       "...      ...             ...      ...         ...     ...            ...   \n",
       "7038       1               0        1           1      24              1   \n",
       "7039       0               0        1           1      72              1   \n",
       "7040       0               0        1           1      11              0   \n",
       "7041       1               1        1           0       4              1   \n",
       "7042       1               0        0           0      66              1   \n",
       "\n",
       "      Multiple Lines  Internet Service  Online Security  Online Backup  \\\n",
       "0                  1                 0                0              2   \n",
       "1                  0                 0                2              0   \n",
       "2                  0                 0                2              2   \n",
       "3                  1                 0                2              0   \n",
       "4                  0                 1                0              0   \n",
       "...              ...               ...              ...            ...   \n",
       "7038               2                 0                2              0   \n",
       "7039               2                 1                0              2   \n",
       "7040               1                 0                2              0   \n",
       "7041               2                 1                0              0   \n",
       "7042               0                 1                2              0   \n",
       "\n",
       "      Device Protection  Tech Support  Streaming TV  Streaming Movies  \\\n",
       "0                     0             0             0                 0   \n",
       "1                     2             0             0                 0   \n",
       "2                     0             0             0                 0   \n",
       "3                     2             2             0                 0   \n",
       "4                     0             0             0                 0   \n",
       "...                 ...           ...           ...               ...   \n",
       "7038                  2             2             2                 2   \n",
       "7039                  2             0             2                 2   \n",
       "7040                  0             0             0                 0   \n",
       "7041                  0             0             0                 0   \n",
       "7042                  2             2             2                 2   \n",
       "\n",
       "      Contract  Paperless Billing  Payment Method  Monthly Charges  \\\n",
       "0            0                  1               2            29.85   \n",
       "1            1                  0               3            56.95   \n",
       "2            0                  1               3            53.85   \n",
       "3            1                  0               0            42.30   \n",
       "4            0                  1               2            70.70   \n",
       "...        ...                ...             ...              ...   \n",
       "7038         1                  1               3            84.80   \n",
       "7039         1                  1               1           103.20   \n",
       "7040         0                  1               2            29.60   \n",
       "7041         0                  1               3            74.40   \n",
       "7042         2                  1               0           105.65   \n",
       "\n",
       "      Total Charges  Churn  \n",
       "0             29.85      0  \n",
       "1           1889.50      0  \n",
       "2            108.15      1  \n",
       "3           1840.75      0  \n",
       "4            151.65      1  \n",
       "...             ...    ...  \n",
       "7038        1990.50      0  \n",
       "7039        7362.90      0  \n",
       "7040         346.45      0  \n",
       "7041         306.60      1  \n",
       "7042        6844.50      0  \n",
       "\n",
       "[7043 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new_custchurn.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5053d99",
   "metadata": {},
   "source": [
    "##### We begin with our model building first step, Spiltting the data into independent and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "babc2227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3521a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:-1]                                      #independent variables\n",
    "y=df.iloc[:,-1]                                        #Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ff4cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 19)\n",
      "(7043,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef9754",
   "metadata": {},
   "source": [
    "##### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0ea315",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f1144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00955867 -0.43991649  1.03453023 ...  0.39855772 -1.16032292\n",
      "  -0.99424193]\n",
      " [ 0.99053183 -0.43991649 -0.96662231 ...  1.33486261 -0.25962894\n",
      "  -0.17324412]\n",
      " [ 0.99053183 -0.43991649 -0.96662231 ...  1.33486261 -0.36266036\n",
      "  -0.95967407]\n",
      " ...\n",
      " [-1.00955867 -0.43991649  1.03453023 ...  0.39855772 -1.1686319\n",
      "  -0.85446944]\n",
      " [ 0.99053183  2.27315869  1.03453023 ...  1.33486261  0.32033821\n",
      "  -0.87206241]\n",
      " [ 0.99053183 -0.43991649 -0.96662231 ... -1.47405205  1.35896134\n",
      "   2.01428802]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()                               \n",
    "scaler.fit(x)                                           #training on data\n",
    "x=scaler.transform(x)                                   #transforming the data\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c436d5c1",
   "metadata": {},
   "source": [
    "Here, we conclude the exploratory data analysis (EDA) and preprocessing steps, transitioning into the model-building phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ae5da",
   "metadata": {},
   "source": [
    "##### Building the model and spilting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3068dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test\n",
    "\n",
    "x_train, x_test,y_train, y_test = train_test_split(x, y, test_size=0.3,\n",
    "                                                   random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6948fc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4930, 19)\n",
      "(4930,)\n",
      "(2113, 19)\n",
      "(2113,)\n",
      "Percentage of train data 69.99858015050404\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"Percentage of train data\",x_train.shape[0]/x.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15a943",
   "metadata": {},
   "source": [
    "### Applying different algorithms to determine which one performs the best , if possible, for tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312ff27",
   "metadata": {},
   "source": [
    "Machine learning alogrithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af08b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, initialize the classificators\n",
    "\n",
    "tree= DecisionTreeClassifier(random_state=77)                       #using the random state for reproducibility\n",
    "knn= KNeighborsClassifier(metric='euclidean')\n",
    "svm=SVC(random_state=77)\n",
    "logreg=LogisticRegression(random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853fb51f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier\n",
      "Accuracy: 72.55\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1568\n",
      "           1       0.47      0.52      0.49       545\n",
      "\n",
      "    accuracy                           0.73      2113\n",
      "   macro avg       0.65      0.66      0.65      2113\n",
      "weighted avg       0.73      0.73      0.73      2113\n",
      "\n",
      "----------------------\n",
      "Model: KNeighborsClassifier\n",
      "Accuracy: 76.34\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1568\n",
      "           1       0.54      0.54      0.54       545\n",
      "\n",
      "    accuracy                           0.76      2113\n",
      "   macro avg       0.69      0.69      0.69      2113\n",
      "weighted avg       0.76      0.76      0.76      2113\n",
      "\n",
      "----------------------\n",
      "Model: SVC\n",
      "Accuracy: 80.03\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1568\n",
      "           1       0.66      0.48      0.55       545\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.74      0.69      0.71      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n",
      "----------------------\n",
      "Model: LogisticRegression\n",
      "Accuracy: 79.93\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1568\n",
      "           1       0.63      0.53      0.58       545\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.74      0.71      0.72      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "#create a list with the objects\n",
    "models = [tree, knn, svm, logreg]\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "model_performance = []\n",
    "\n",
    "for model in models:\n",
    "    model.fit(x_train, y_train)                                  # Fit the model\n",
    "    y_pred = model.predict(x_test)                               # Then predict on the test set\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    class_repo = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Store each model's performance metrics in a dictionary and add it to the list\n",
    "    performance = {\n",
    "        'Model': type(model).__name__,\n",
    "        'Accuracy': round(accuracy*100,2),\n",
    "        'Precision': round(precision*100,2),\n",
    "        'Recall': round(recall*100,2)\n",
    "    }\n",
    "    model_performance.append(performance)\n",
    "    \n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(f'Accuracy: {round(accuracy*100,2)}')\n",
    "    print(f'Classification report: \\n{class_repo}')\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78608723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>72.55</td>\n",
       "      <td>64.83</td>\n",
       "      <td>65.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>76.34</td>\n",
       "      <td>69.08</td>\n",
       "      <td>69.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>80.03</td>\n",
       "      <td>74.46</td>\n",
       "      <td>69.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>79.93</td>\n",
       "      <td>73.88</td>\n",
       "      <td>71.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision  Recall\n",
       "0  DecisionTreeClassifier     72.55      64.83   65.70\n",
       "1    KNeighborsClassifier     76.34      69.08   69.03\n",
       "2                     SVC     80.03      74.46   69.42\n",
       "3      LogisticRegression     79.93      73.88   71.22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of performance metrics into a DataFrame for a nice table view\n",
    "performance_df = pd.DataFrame(model_performance)\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7895520",
   "metadata": {},
   "source": [
    "Applying Ensemble Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c6bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, initialize the classificators\n",
    "\n",
    "ensemble_models = [RandomForestClassifier(n_estimators=100, random_state=77),\n",
    "                   ExtraTreesClassifier(n_estimators=100, random_state=77),\n",
    "                   GradientBoostingClassifier(n_estimators=100, random_state=77),\n",
    "                   AdaBoostClassifier(n_estimators=100, random_state=77),\n",
    "                   XGBClassifier(random_state=77)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4daeec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "Accuracy: 78.47\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1568\n",
      "           1       0.61      0.48      0.53       545\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.72      0.68      0.70      2113\n",
      "weighted avg       0.77      0.78      0.78      2113\n",
      "\n",
      "----------------------\n",
      "Model: ExtraTreesClassifier\n",
      "Accuracy: 78.14\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86      1568\n",
      "           1       0.59      0.48      0.53       545\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.71      0.68      0.70      2113\n",
      "weighted avg       0.77      0.78      0.77      2113\n",
      "\n",
      "----------------------\n",
      "Model: GradientBoostingClassifier\n",
      "Accuracy: 80.36\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      1568\n",
      "           1       0.65      0.51      0.57       545\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.75      0.71      0.72      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n",
      "----------------------\n",
      "Model: AdaBoostClassifier\n",
      "Accuracy: 80.12\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      1568\n",
      "           1       0.64      0.53      0.58       545\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.74      0.71      0.72      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n",
      "----------------------\n",
      "Model: XGBClassifier\n",
      "Accuracy: 77.57\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      1568\n",
      "           1       0.58      0.48      0.53       545\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.70      0.68      0.69      2113\n",
      "weighted avg       0.77      0.78      0.77      2113\n",
      "\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store results\n",
    "model_performance = []\n",
    "\n",
    "for model in ensemble_models:\n",
    "    model.fit(x_train, y_train)                                  # Fit the model\n",
    "    y_pred = model.predict(x_test)                               # Then predict on the test set\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    class_repo = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Store each model's performance metrics in a dictionary and add it to the list\n",
    "    performance = {\n",
    "        'Model': type(model).__name__,\n",
    "        'Accuracy': round(accuracy*100,2),\n",
    "        'Precision': round(precision*100,2),\n",
    "        'Recall': round(recall*100,2)\n",
    "    }\n",
    "    model_performance.append(performance)\n",
    "    \n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(f'Accuracy: {round(accuracy*100,2)}')\n",
    "    print(f'Classification report: \\n{class_repo}')\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d7d3ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>78.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>68.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>78.14</td>\n",
       "      <td>71.24</td>\n",
       "      <td>68.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>80.36</td>\n",
       "      <td>74.75</td>\n",
       "      <td>70.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>80.12</td>\n",
       "      <td>74.19</td>\n",
       "      <td>71.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>77.57</td>\n",
       "      <td>70.40</td>\n",
       "      <td>68.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy  Precision  Recall\n",
       "0      RandomForestClassifier     78.47      71.77   68.37\n",
       "1        ExtraTreesClassifier     78.14      71.24   68.45\n",
       "2  GradientBoostingClassifier     80.36      74.75   70.67\n",
       "3          AdaBoostClassifier     80.12      74.19   71.28\n",
       "4               XGBClassifier     77.57      70.40   68.07"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of performance metrics into a DataFrame for a nice table view\n",
    "performance_df_ens = pd.DataFrame(model_performance)\n",
    "performance_df_ens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e14b6c",
   "metadata": {},
   "source": [
    "Building a neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb317f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c54973f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "148/155 [===========================>..] - ETA: 0s - loss: 0.5320 - accuracy: 0.7276\n",
      "Epoch 1: val_loss improved from inf to 0.45506, saving model to best_model.h5\n",
      "155/155 [==============================] - 3s 6ms/step - loss: 0.5303 - accuracy: 0.7290 - val_loss: 0.4551 - val_accuracy: 0.7757\n",
      "Epoch 2/100\n",
      "145/155 [===========================>..] - ETA: 0s - loss: 0.4670 - accuracy: 0.7681\n",
      "Epoch 2: val_loss improved from 0.45506 to 0.44538, saving model to best_model.h5\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4636 - accuracy: 0.7710 - val_loss: 0.4454 - val_accuracy: 0.7837\n",
      "Epoch 3/100\n",
      "143/155 [==========================>...] - ETA: 0s - loss: 0.4490 - accuracy: 0.7734\n",
      "Epoch 3: val_loss improved from 0.44538 to 0.43458, saving model to best_model.h5\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4483 - accuracy: 0.7767 - val_loss: 0.4346 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "139/155 [=========================>....] - ETA: 0s - loss: 0.4443 - accuracy: 0.7855\n",
      "Epoch 4: val_loss improved from 0.43458 to 0.43361, saving model to best_model.h5\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.4384 - accuracy: 0.7884 - val_loss: 0.4336 - val_accuracy: 0.7885\n",
      "Epoch 5/100\n",
      "137/155 [=========================>....] - ETA: 0s - loss: 0.4372 - accuracy: 0.7920\n",
      "Epoch 5: val_loss improved from 0.43361 to 0.42943, saving model to best_model.h5\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4343 - accuracy: 0.7933 - val_loss: 0.4294 - val_accuracy: 0.7918\n",
      "Epoch 6/100\n",
      "151/155 [============================>.] - ETA: 0s - loss: 0.4318 - accuracy: 0.7933\n",
      "Epoch 6: val_loss improved from 0.42943 to 0.42641, saving model to best_model.h5\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4305 - accuracy: 0.7941 - val_loss: 0.4264 - val_accuracy: 0.7946\n",
      "Epoch 7/100\n",
      "143/155 [==========================>...] - ETA: 0s - loss: 0.4220 - accuracy: 0.7985\n",
      "Epoch 7: val_loss improved from 0.42641 to 0.42430, saving model to best_model.h5\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4254 - accuracy: 0.7955 - val_loss: 0.4243 - val_accuracy: 0.7951\n",
      "Epoch 8/100\n",
      "145/155 [===========================>..] - ETA: 0s - loss: 0.4225 - accuracy: 0.7991\n",
      "Epoch 8: val_loss did not improve from 0.42430\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4241 - accuracy: 0.7970 - val_loss: 0.4248 - val_accuracy: 0.7993\n",
      "Epoch 9/100\n",
      "142/155 [==========================>...] - ETA: 0s - loss: 0.4227 - accuracy: 0.7975\n",
      "Epoch 9: val_loss did not improve from 0.42430\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.7972 - val_loss: 0.4257 - val_accuracy: 0.7998\n",
      "Epoch 10/100\n",
      "140/155 [==========================>...] - ETA: 0s - loss: 0.4210 - accuracy: 0.8011\n",
      "Epoch 10: val_loss improved from 0.42430 to 0.42424, saving model to best_model.h5\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4191 - accuracy: 0.8026 - val_loss: 0.4242 - val_accuracy: 0.7970\n",
      "Epoch 11/100\n",
      "137/155 [=========================>....] - ETA: 0s - loss: 0.4116 - accuracy: 0.8041\n",
      "Epoch 11: val_loss improved from 0.42424 to 0.42245, saving model to best_model.h5\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4145 - accuracy: 0.8030 - val_loss: 0.4224 - val_accuracy: 0.8008\n",
      "Epoch 12/100\n",
      "152/155 [============================>.] - ETA: 0s - loss: 0.4152 - accuracy: 0.8047\n",
      "Epoch 12: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4147 - accuracy: 0.8053 - val_loss: 0.4284 - val_accuracy: 0.7960\n",
      "Epoch 13/100\n",
      "135/155 [=========================>....] - ETA: 0s - loss: 0.4100 - accuracy: 0.8095\n",
      "Epoch 13: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4109 - accuracy: 0.8083 - val_loss: 0.4239 - val_accuracy: 0.7989\n",
      "Epoch 14/100\n",
      "139/155 [=========================>....] - ETA: 0s - loss: 0.4074 - accuracy: 0.8107\n",
      "Epoch 14: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4097 - accuracy: 0.8087 - val_loss: 0.4248 - val_accuracy: 0.7970\n",
      "Epoch 15/100\n",
      "144/155 [==========================>...] - ETA: 0s - loss: 0.4088 - accuracy: 0.8082\n",
      "Epoch 15: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8079 - val_loss: 0.4264 - val_accuracy: 0.7932\n",
      "Epoch 16/100\n",
      "148/155 [===========================>..] - ETA: 0s - loss: 0.4029 - accuracy: 0.8102\n",
      "Epoch 16: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.4026 - accuracy: 0.8116 - val_loss: 0.4332 - val_accuracy: 0.7927\n",
      "Epoch 17/100\n",
      "148/155 [===========================>..] - ETA: 0s - loss: 0.4033 - accuracy: 0.8119\n",
      "Epoch 17: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8120 - val_loss: 0.4279 - val_accuracy: 0.7984\n",
      "Epoch 18/100\n",
      "150/155 [============================>.] - ETA: 0s - loss: 0.4058 - accuracy: 0.8079\n",
      "Epoch 18: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8089 - val_loss: 0.4282 - val_accuracy: 0.7960\n",
      "Epoch 19/100\n",
      "144/155 [==========================>...] - ETA: 0s - loss: 0.4040 - accuracy: 0.8138\n",
      "Epoch 19: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.4031 - accuracy: 0.8136 - val_loss: 0.4286 - val_accuracy: 0.7941\n",
      "Epoch 20/100\n",
      "138/155 [=========================>....] - ETA: 0s - loss: 0.4001 - accuracy: 0.8130\n",
      "Epoch 20: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3999 - accuracy: 0.8134 - val_loss: 0.4295 - val_accuracy: 0.7922\n",
      "Epoch 21/100\n",
      "146/155 [===========================>..] - ETA: 0s - loss: 0.4005 - accuracy: 0.8151\n",
      "Epoch 21: val_loss did not improve from 0.42245\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3985 - accuracy: 0.8158 - val_loss: 0.4321 - val_accuracy: 0.7918\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1499e526390>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "model_ann = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model_ann.add(Dense(units = 19, activation = 'relu', input_dim = 19))\n",
    "\n",
    "\n",
    "# Adding the second hidden layer \n",
    "model_ann.add(Dense(units=19, activation='relu'))\n",
    "\n",
    "# dropout for second layer \n",
    "model_ann.add(Dropout(0.1))\n",
    "\n",
    "# Adding the third hidden layer \n",
    "model_ann.add(Dense(units=19, activation='relu'))\n",
    "\n",
    "# dropout for third layer \n",
    "model_ann.add(Dropout(0.1))\n",
    "\n",
    "# Adding the fourth hidden layer \n",
    "model_ann.add(Dense(units=19, activation='relu'))\n",
    "\n",
    "\n",
    "# Adding the output layer \n",
    "model_ann.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "model_ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_ann.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "332fa0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 19)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 19)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1540 (6.02 KB)\n",
      "Trainable params: 1540 (6.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9dca141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 2ms/step\n",
      "Accuracy: 80.08\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1568\n",
      "           1       0.64      0.52      0.57       545\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.74      0.71      0.72      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model_ann = load_model('best_model.h5')\n",
    "\n",
    "# Predict class probabilities\n",
    "y_pred_probs = model_ann.predict(x_test)\n",
    "\n",
    "# Convert probabilities to class labels based on a 0.5 threshold\n",
    "y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "class_repo = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(accuracy * 100, 2)}')\n",
    "print(f'Classification report: \\n{class_repo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512e227",
   "metadata": {},
   "source": [
    "We can clearly see that the accuracy of most algorithms, including the neural network, is around 80%, with the best-performing models being AdaBoost and Gradient Boosting. However, it's important to remember that the dataset is imbalanced. To address this issue, we will use SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe463995",
   "metadata": {},
   "source": [
    "#### SMOTE\n",
    "Synthetic minority oversampling Technique. This technique allows us to upsample the minority class observation to reach the level of majority class by creating synthetic samples similar to existing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4ac8fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5174\n",
       "1    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df68b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 19)\n",
      "(7043,)\n"
     ]
    }
   ],
   "source": [
    "X = df.values[:,:-1]\n",
    "Y = df.values[:,-1]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50f35632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa4fd320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "443975d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1':  1312\n",
      "Before OverSampling, counts of label '0':  3618\n",
      "After OverSampling, the shape of train_X:  (7236, 19)\n",
      "After OverSampling, the shape of train_y:  (7236,)\n",
      "After OverSampling, counts of label '1':  3618\n",
      "After OverSampling, counts of label '0':  3618\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': \", (sum(Y_train == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': \", (sum(Y_train == 0)))\n",
    "  \n",
    "# import SMOTE from imblearn library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 77,k_neighbors=10)\n",
    "x_train_new, y_train_new = sm.fit_resample(X_train, Y_train)\n",
    "  \n",
    "print('After OverSampling, the shape of train_X: ', (x_train_new.shape))\n",
    "print('After OverSampling, the shape of train_y: ', (y_train_new.shape))\n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': \", (sum(y_train_new == 1)))\n",
    "print(\"After OverSampling, counts of label '0': \", (sum(y_train_new == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932aacc",
   "metadata": {},
   "source": [
    "Applying tradtional ML algo on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7246f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier\n",
      "Accuracy: 71.42\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.78      0.80      1556\n",
      "         1.0       0.46      0.53      0.49       557\n",
      "\n",
      "    accuracy                           0.71      2113\n",
      "   macro avg       0.64      0.66      0.65      2113\n",
      "weighted avg       0.73      0.71      0.72      2113\n",
      "\n",
      "----------------------\n",
      "Model: KNeighborsClassifier\n",
      "Accuracy: 66.26\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.66      0.74      1556\n",
      "         1.0       0.41      0.68      0.52       557\n",
      "\n",
      "    accuracy                           0.66      2113\n",
      "   macro avg       0.63      0.67      0.63      2113\n",
      "weighted avg       0.74      0.66      0.68      2113\n",
      "\n",
      "----------------------\n",
      "Model: SVC\n",
      "Accuracy: 75.77\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.78      0.83      1556\n",
      "         1.0       0.53      0.70      0.60       557\n",
      "\n",
      "    accuracy                           0.76      2113\n",
      "   macro avg       0.70      0.74      0.71      2113\n",
      "weighted avg       0.79      0.76      0.77      2113\n",
      "\n",
      "----------------------\n",
      "Model: LogisticRegression\n",
      "Accuracy: 75.11\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.74      0.81      1556\n",
      "         1.0       0.52      0.79      0.62       557\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.71      0.76      0.72      2113\n",
      "weighted avg       0.80      0.75      0.76      2113\n",
      "\n",
      "----------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>71.42</td>\n",
       "      <td>64.31</td>\n",
       "      <td>65.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>66.26</td>\n",
       "      <td>63.35</td>\n",
       "      <td>66.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>75.77</td>\n",
       "      <td>70.42</td>\n",
       "      <td>73.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>75.11</td>\n",
       "      <td>71.22</td>\n",
       "      <td>76.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision  Recall\n",
       "0  DecisionTreeClassifier     71.42      64.31   65.55\n",
       "1    KNeighborsClassifier     66.26      63.35   66.89\n",
       "2                     SVC     75.77      70.42   73.81\n",
       "3      LogisticRegression     75.11      71.22   76.24"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, initialize the classificators\n",
    "\n",
    "tree= DecisionTreeClassifier(random_state=77)                       #using the random state for reproducibility\n",
    "knn= KNeighborsClassifier(metric='euclidean')\n",
    "svm=SVC(random_state=77)\n",
    "logreg=LogisticRegression(random_state=77)\n",
    "\n",
    "#create a list with the objects\n",
    "models = [tree, knn, svm, logreg]\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "model_performance = []\n",
    "\n",
    "for model in models:\n",
    "    model.fit(x_train_new, y_train_new)                                  # Fit the model\n",
    "    y_pred = model.predict(X_test)                               # Then predict on the test set\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred, average='macro')\n",
    "    recall = recall_score(Y_test, y_pred, average='macro')\n",
    "    class_repo = classification_report(Y_test, y_pred)\n",
    "    \n",
    "    # Store each model's performance metrics in a dictionary and add it to the list\n",
    "    performance = {\n",
    "        'Model': type(model).__name__,\n",
    "        'Accuracy': round(accuracy*100,2),\n",
    "        'Precision': round(precision*100,2),\n",
    "        'Recall': round(recall*100,2)\n",
    "    }\n",
    "    model_performance.append(performance)\n",
    "    \n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(f'Accuracy: {round(accuracy*100,2)}')\n",
    "    print(f'Classification report: \\n{class_repo}')\n",
    "    print(\"----------------------\")\n",
    "\n",
    "# Convert the list of performance metrics into a DataFrame for a nice table view\n",
    "performance_df_smote = pd.DataFrame(model_performance)\n",
    "performance_df_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c586b3",
   "metadata": {},
   "source": [
    "Applying Ensemble Techniques on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc863408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "Accuracy: 77.8\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85      1556\n",
      "         1.0       0.58      0.58      0.58       557\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.71      0.71      0.71      2113\n",
      "weighted avg       0.78      0.78      0.78      2113\n",
      "\n",
      "----------------------\n",
      "Model: ExtraTreesClassifier\n",
      "Accuracy: 76.67\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.84      1556\n",
      "         1.0       0.56      0.51      0.54       557\n",
      "\n",
      "    accuracy                           0.77      2113\n",
      "   macro avg       0.70      0.68      0.69      2113\n",
      "weighted avg       0.76      0.77      0.76      2113\n",
      "\n",
      "----------------------\n",
      "Model: GradientBoostingClassifier\n",
      "Accuracy: 79.46\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.83      0.86      1556\n",
      "         1.0       0.60      0.69      0.64       557\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.76      0.75      2113\n",
      "weighted avg       0.81      0.79      0.80      2113\n",
      "\n",
      "----------------------\n",
      "Model: AdaBoostClassifier\n",
      "Accuracy: 78.04\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.81      0.84      1556\n",
      "         1.0       0.57      0.70      0.63       557\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.73      0.75      0.74      2113\n",
      "weighted avg       0.80      0.78      0.79      2113\n",
      "\n",
      "----------------------\n",
      "Model: XGBClassifier\n",
      "Accuracy: 78.42\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85      1556\n",
      "         1.0       0.59      0.59      0.59       557\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.72      0.72      0.72      2113\n",
      "weighted avg       0.78      0.78      0.78      2113\n",
      "\n",
      "----------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>77.80</td>\n",
       "      <td>71.40</td>\n",
       "      <td>71.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>76.67</td>\n",
       "      <td>69.70</td>\n",
       "      <td>68.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>79.46</td>\n",
       "      <td>73.86</td>\n",
       "      <td>76.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>78.04</td>\n",
       "      <td>72.53</td>\n",
       "      <td>75.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>78.42</td>\n",
       "      <td>72.20</td>\n",
       "      <td>72.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy  Precision  Recall\n",
       "0      RandomForestClassifier     77.80      71.40   71.33\n",
       "1        ExtraTreesClassifier     76.67      69.70   68.48\n",
       "2  GradientBoostingClassifier     79.46      73.86   76.03\n",
       "3          AdaBoostClassifier     78.04      72.53   75.47\n",
       "4               XGBClassifier     78.42      72.20   72.15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, initialize the classificators\n",
    "\n",
    "ensemble_models = [RandomForestClassifier(n_estimators=100, random_state=77),\n",
    "                   ExtraTreesClassifier(n_estimators=100, random_state=77),\n",
    "                   GradientBoostingClassifier(n_estimators=100, random_state=77),\n",
    "                   AdaBoostClassifier(n_estimators=100, random_state=77),\n",
    "                   XGBClassifier(random_state=77)]\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "model_performance = []\n",
    "\n",
    "for model in ensemble_models:\n",
    "    model.fit(x_train_new, y_train_new)                                  # Fit the model\n",
    "    y_pred = model.predict(X_test)                               # Then predict on the test set\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred, average='macro')\n",
    "    recall = recall_score(Y_test, y_pred, average='macro')\n",
    "    class_repo = classification_report(Y_test, y_pred)\n",
    "    \n",
    "    # Store each model's performance metrics in a dictionary and add it to the list\n",
    "    performance = {\n",
    "        'Model': type(model).__name__,\n",
    "        'Accuracy': round(accuracy*100,2),\n",
    "        'Precision': round(precision*100,2),\n",
    "        'Recall': round(recall*100,2)\n",
    "    }\n",
    "    model_performance.append(performance)\n",
    "    \n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(f'Accuracy: {round(accuracy*100,2)}')\n",
    "    print(f'Classification report: \\n{class_repo}')\n",
    "    print(\"----------------------\")\n",
    "\n",
    "# Convert the list of performance metrics into a DataFrame for a nice table view\n",
    "performance_df_ens_smote = pd.DataFrame(model_performance)\n",
    "performance_df_ens_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c9f36",
   "metadata": {},
   "source": [
    "Building a neural Network on SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e33721e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "218/227 [===========================>..] - ETA: 0s - loss: 0.5370 - accuracy: 0.7407\n",
      "Epoch 1: val_loss improved from inf to 0.51738, saving model to best_model1.h5\n",
      "227/227 [==============================] - 3s 5ms/step - loss: 0.5366 - accuracy: 0.7412 - val_loss: 0.5174 - val_accuracy: 0.7350\n",
      "Epoch 2/100\n",
      "219/227 [===========================>..] - ETA: 0s - loss: 0.4821 - accuracy: 0.7744\n",
      "Epoch 2: val_loss improved from 0.51738 to 0.50740, saving model to best_model1.h5\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4816 - accuracy: 0.7746 - val_loss: 0.5074 - val_accuracy: 0.7388\n",
      "Epoch 3/100\n",
      "225/227 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7793\n",
      "Epoch 3: val_loss did not improve from 0.50740\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.4712 - accuracy: 0.7794 - val_loss: 0.5134 - val_accuracy: 0.7378\n",
      "Epoch 4/100\n",
      "220/227 [============================>.] - ETA: 0s - loss: 0.4591 - accuracy: 0.7837\n",
      "Epoch 4: val_loss improved from 0.50740 to 0.47519, saving model to best_model1.h5\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4614 - accuracy: 0.7819 - val_loss: 0.4752 - val_accuracy: 0.7572\n",
      "Epoch 5/100\n",
      "212/227 [===========================>..] - ETA: 0s - loss: 0.4550 - accuracy: 0.7854\n",
      "Epoch 5: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.4540 - accuracy: 0.7866 - val_loss: 0.5113 - val_accuracy: 0.7411\n",
      "Epoch 6/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.4515 - accuracy: 0.7871\n",
      "Epoch 6: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.7870 - val_loss: 0.4853 - val_accuracy: 0.7553\n",
      "Epoch 7/100\n",
      "223/227 [============================>.] - ETA: 0s - loss: 0.4457 - accuracy: 0.7906\n",
      "Epoch 7: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4456 - accuracy: 0.7905 - val_loss: 0.5046 - val_accuracy: 0.7402\n",
      "Epoch 8/100\n",
      "218/227 [===========================>..] - ETA: 0s - loss: 0.4424 - accuracy: 0.7917\n",
      "Epoch 8: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4430 - accuracy: 0.7922 - val_loss: 0.5169 - val_accuracy: 0.7478\n",
      "Epoch 9/100\n",
      "224/227 [============================>.] - ETA: 0s - loss: 0.4381 - accuracy: 0.7966\n",
      "Epoch 9: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4393 - accuracy: 0.7957 - val_loss: 0.5090 - val_accuracy: 0.7454\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.7951\n",
      "Epoch 10: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4396 - accuracy: 0.7951 - val_loss: 0.5006 - val_accuracy: 0.7430\n",
      "Epoch 11/100\n",
      "223/227 [============================>.] - ETA: 0s - loss: 0.4343 - accuracy: 0.7989\n",
      "Epoch 11: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4344 - accuracy: 0.7991 - val_loss: 0.5016 - val_accuracy: 0.7515\n",
      "Epoch 12/100\n",
      "207/227 [==========================>...] - ETA: 0s - loss: 0.4314 - accuracy: 0.7965\n",
      "Epoch 12: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4298 - accuracy: 0.7977 - val_loss: 0.5062 - val_accuracy: 0.7468\n",
      "Epoch 13/100\n",
      "225/227 [============================>.] - ETA: 0s - loss: 0.4313 - accuracy: 0.7986\n",
      "Epoch 13: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4954 - val_accuracy: 0.7534\n",
      "Epoch 14/100\n",
      "225/227 [============================>.] - ETA: 0s - loss: 0.4242 - accuracy: 0.8044\n",
      "Epoch 14: val_loss did not improve from 0.47519\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8043 - val_loss: 0.5063 - val_accuracy: 0.7478\n",
      "Epoch 14: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x149a4eebb10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "model_ann_sm = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model_ann_sm.add(Dense(units = 19, activation = 'relu', input_dim = 19))\n",
    "\n",
    "\n",
    "# Adding the second hidden layer \n",
    "model_ann_sm.add(Dense(units=19, activation='relu'))\n",
    "\n",
    "# dropout for second layer \n",
    "model_ann_sm.add(Dropout(0.1))\n",
    "\n",
    "# Adding the third hidden layer \n",
    "model_ann_sm.add(Dense(units=19, activation='relu'))\n",
    "\n",
    "# dropout for third layer \n",
    "model_ann_sm.add(Dropout(0.1))\n",
    "\n",
    "# Adding the fourth hidden layer \n",
    "model_ann_sm.add(Dense(units=19, activation='relu'))\n",
    "\n",
    "\n",
    "# Adding the output layer \n",
    "model_ann_sm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "model_ann_sm.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "model_checkpoint = ModelCheckpoint('best_model1.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_ann_sm.fit(x_train_new, y_train_new, validation_data=(X_test, Y_test), epochs=100, callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76af51f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 2ms/step\n",
      "Accuracy: 75.72\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.76      0.82      1556\n",
      "         1.0       0.53      0.74      0.62       557\n",
      "\n",
      "    accuracy                           0.76      2113\n",
      "   macro avg       0.71      0.75      0.72      2113\n",
      "weighted avg       0.80      0.76      0.77      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model_ann_sm = load_model('best_model1.h5')\n",
    "\n",
    "# Predict class probabilities\n",
    "y_pred_probs = model_ann_sm.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels based on a 0.5 threshold\n",
    "y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "class_repo = classification_report(Y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(accuracy * 100, 2)}')\n",
    "print(f'Classification report: \\n{class_repo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c5ff2",
   "metadata": {},
   "source": [
    "We can infer that out of all the algorithms, Gradient Boosting and AdaBoost perform the best. However, we have selected Gradient Boosting for further fine-tuning the model because it has almost the same recall for the minority class but with better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197bfbc",
   "metadata": {},
   "source": [
    "###### Hyperparameter Tuinig using RandomizedSearchCV.<br>\n",
    "\n",
    "RandomizedSearchCV is a hyperparameter tuning technique in machine learning that is used to find the best parameters for a model. It generates a grid of hyperparameter values and randomly selects combinations to train the model and score. This allows users to control the number of parameter combinations that are attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "79e0964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Hyperparameters: {'criterion': 'friedman_mse', 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 126}\n",
      "Best Score: 0.8570952064372663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distribtuion to search\n",
    "param_dist = {\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'n_estimators': randint(100, 200),               # Uniformly sample over the given range\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 6),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "model_GB = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model_GB, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, verbose=3, random_state=42, n_jobs=-1,\n",
    "                                   scoring='recall')\n",
    "\n",
    "# Fit RandomizedSearchCV to the data\n",
    "random_search.fit(x_train_new, y_train_new)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5e96adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.23\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85      1556\n",
      "         1.0       0.59      0.58      0.58       557\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.72      0.72      0.72      2113\n",
      "weighted avg       0.78      0.78      0.78      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# buidling a model using Randomsearchcv parameters\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "class_repo = classification_report(Y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(accuracy * 100, 2)}')\n",
    "print(f'Classification report: \\n{class_repo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479d56b",
   "metadata": {},
   "source": [
    "Base Gradient boosting model on Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff912297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.46\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.83      0.86      1556\n",
      "         1.0       0.60      0.69      0.64       557\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.76      0.75      2113\n",
      "weighted avg       0.81      0.79      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingClassifier(random_state=77)\n",
    "\n",
    "model_gb.fit(x_train_new,y_train_new)\n",
    "y_pred = model_gb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "class_repo = classification_report(Y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(accuracy * 100, 2)}')\n",
    "print(f'Classification report: \\n{class_repo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9703481c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.95\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.81      0.84      1556\n",
      "         1.0       0.57      0.70      0.63       557\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.72      0.75      0.73      2113\n",
      "weighted avg       0.80      0.78      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_gb_tuned = GradientBoostingClassifier(\n",
    "    n_estimators=1000,  \n",
    "    learning_rate=0.001, \n",
    "    max_depth=7,  # Shallower trees\n",
    "    min_samples_split=3,  \n",
    "    min_samples_leaf=1,\n",
    "    #subsample=0.8,  # Subsampling 80% of the data\n",
    "    random_state=77  # For reproducibility\n",
    ")\n",
    "\n",
    "# Train the model on the entire training set\n",
    "model_gb_tuned.fit(x_train_new, y_train_new)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_gb_tuned.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "class_repo = classification_report(Y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {round(accuracy * 100, 2)}')\n",
    "print(f'Classification report: \\n{class_repo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8950d",
   "metadata": {},
   "source": [
    "Since there is no increase in performace of model, we'll try subsetting some features using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "581c477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22587257 0.12599686 0.07656962 0.06444913 0.05827133 0.05386417\n",
      " 0.0527947  0.04386427 0.04146521 0.03932528 0.03886149 0.03463311\n",
      " 0.03367991 0.03127884 0.02835668 0.02312644]\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.95)                  #to view the entire eigen vector,no subsetting\n",
    "x_train_pca = pca.fit_transform(x_train_new)\n",
    "x_test_pca = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7bf1e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "483bd4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.73\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.74      0.81      1556\n",
      "         1.0       0.51      0.76      0.61       557\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.71      0.75      0.71      2113\n",
      "weighted avg       0.80      0.75      0.76      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_gb_pca = GradientBoostingClassifier(random_state=77)\n",
    "\n",
    "model_gb_pca.fit(x_train_pca,y_train_new)\n",
    "y_pred = model_gb_pca.predict(x_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "class_repo = classification_report(Y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(accuracy * 100, 2)}')\n",
    "print(f'Classification report: \\n{class_repo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c43315",
   "metadata": {},
   "source": [
    "After using PCA and exploring various options for tuning to optimize our model, we found that our base Gradient Boosting model performs better in terms of accuracy and recall. Therefore, it will be used for further model deployment and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c393e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4333db7a",
   "metadata": {},
   "source": [
    "Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2615bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ce8634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filname = 'model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36968870",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_gb, open(filname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78916ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = pickle.load(open(filname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c88c21e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7946048272598202"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d3a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
